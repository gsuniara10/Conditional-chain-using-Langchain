from langchain_groq import ChatGroq
from langchain_core.prompts import PromptTemplate
from langchain_core.output_parsers import StrOutputParser, PydanticOutputParser
from langchain.schema.runnable import RunnableParallel, RunnableBranch, RunnableLambda
from pydantic import BaseModel, Field
from typing import Literal
from dotenv import load_dotenv

load_dotenv()

llm  = ChatGroq(
     model="llama-3.1-8b-instant"
)

class feedback_analysis(BaseModel):
    sentimental_analysis_1 : Literal["positive","negative"] = Field(description="provide the sentimental of the given review in positive or negative")

pydantic_parser = PydanticOutputParser(pydantic_object=feedback_analysis) 

first_prompt = PromptTemplate(
    template=" Please classify the sentiment of the following text into positive or negative \n {feedback_analysis} \n {format_instruction}",
    input_variables=["sentimental_analysis"],
    partial_variables={'format_instruction':pydantic_parser.get_format_instructions()}
)

simple_chain = first_prompt | llm | pydantic_parser

second_prompt = PromptTemplate(
    template= "Your an expert support assistance, Please write an appropriate response to this positive feedback \n {feedback_analysis}",
    input_variables=["feedback_analysis"]
)

third_prompt = PromptTemplate(
    template= "Your an expert support assistance, Please write an appropriate response to this negative feedback \n {feedback_analysis}",
    input_variables=["feedback_analysis"]
)

string_parser = StrOutputParser()

conditional_chain = RunnableBranch(
    (lambda x:x.sentimental_analysis_1 == 'positive', second_prompt | llm | string_parser),
    (lambda x:x.sentimental_analysis_1 == 'negative', third_prompt | llm | string_parser),
    RunnableLambda(lambda x:"could not find the sentiment")

)


final_chain = simple_chain | conditional_chain

query = input("Enter the topic : ")

final_chain_output = final_chain.invoke({'feedback_analysis':query})

print(final_chain_output)

final_chain.get_graph().print_ascii()
